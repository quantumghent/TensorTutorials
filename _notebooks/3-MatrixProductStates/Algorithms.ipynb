{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6e77df7d",
   "metadata": {},
   "source": [
    "# A Simple Tensor Network Algorithm\n",
    "\n",
    "Having introduced tensor networks in general, with a focus on the case of MPS, we now turn\n",
    "to the question of how to use them to solve specific problems. While a large number of\n",
    "tensor network algorithms have been developed, many of them more advanced and/or efficient\n",
    "than the ones we will discuss here, we will focus on a few simple algorithms that are easy\n",
    "to understand and implement. Importantly, these algorithms are also the building blocks of\n",
    "more advanced algorithms, for example in higher spatial dimensions.\n",
    "\n",
    "Effectively, we have already seen how to use MPS to compute expectation values or\n",
    "correlation functions, or derive all kind of properties. Here, we focus on how to obtain the\n",
    "desired MPS in the first place. In other words, given a certain problem, how can we optimize\n",
    "an MPS, or a more general tensor network, to solve it?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eea04a5e",
   "metadata": {},
   "source": [
    "## Simulating Quantum Systems\n",
    "\n",
    "As a first example, let us consider the problem of simulating a quantum system. We can\n",
    "formalize this idea as follows: Given a Hamiltonian $ H $, and some initial state\n",
    "$ \\ket{\\psi_0} $ at time $ t=0 $, is there a way to compute the *time-evolved state*\n",
    "$ \\ket{\\psi(t)} = e^{-i H t} \\ket{\\psi_0} $ at some later time $ t $.\n",
    "\n",
    "In general, this is a very hard problem. For example, one could naively try to\n",
    "[compute the matrix exponential](https://en.wikipedia.org/wiki/Matrix_exponential#Computing_the_matrix_exponential),\n",
    "but this quickly becomes prohibitively expensive, as the dimension of the Hamiltonian scales\n",
    "exponentially with the number of particles. However, for physically relevant systems the\n",
    "Hamiltonian does not consist of a random matrix, but rather exhibits additional structure\n",
    "that can be used to simplify the problem.\n",
    "\n",
    "\n",
    "<a id='tebd'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3767edde",
   "metadata": {},
   "source": [
    "## Time-Evolving Block Decimation (TEBD)\n",
    "\n",
    "A particularly powerful example can be found for systems with local interactions, where the\n",
    "Hamiltonian is of the form:\n",
    "\n",
    "$$\n",
    "H = \\sum_{i,j} h_{ij}\n",
    "$$\n",
    "\n",
    "where $ h_{ij} $ denotes a local operator, acting only on a small number of sites. In this\n",
    "case, although $ e^{-i H t} $ is unfeasible to compute, each of the constituent terms act only\n",
    "on a much smaller subsystem and therefore $ e^{-ih_{ij}t} $ can be computed efficiently.\n",
    "However, as these terms generally do not commute, we cannot simply apply them one after the\n",
    "other. Instead, we can use the first-order Suzuki-Trotter decomposition to approximate the\n",
    "time-evolution operator, which states that for any two Hermitian operators $ A $ and $ B $, and\n",
    "any real number $ \\Delta t $, we have:\n",
    "\n",
    "\n",
    "<a id='equation-trotter-first'></a>\n",
    "$$\n",
    "e^{(A + B) \\Delta t} = e^{A \\Delta t} e^{B \\Delta t} + \\mathcal O(\\Delta t^2). \\tag{14.1}\n",
    "$$\n",
    "\n",
    "If we now split the full time interval $ t $ into $ m $ steps, we obtain the approximation\n",
    "\n",
    "$$\n",
    "e^{-i H t} = \\left( e^{-i H_e \\frac{t}{m}} e^{-i H_o \\frac{t}{m}} \\right)^m + \\mathcal O\n",
    "\\left( \\frac{t^2}{m}\\right)\n",
    "$$\n",
    "\n",
    "where the approximation error can be managed by choosing a sufficiently large $ m $.\n",
    "\n",
    ">**Note**\n",
    ">\n",
    ">There actually exist entire families of such exponential product approximations up to a\n",
    "given order [[Hatano and Suzuki, 2005](https://quantumghent.github.io/TensorTutorials/../References.html#id16)]. For our purposes however, it is sufficient to\n",
    "illustrate a simulation procedure using this first-order approximation."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "920199eb",
   "metadata": {},
   "source": [
    "### Example: One-Dimensional Nearest-Neighbor Hamiltonians\n",
    "\n",
    "We can put the discussion above into practice by applying it to the example of a nearest-neighbour Hamiltonian on a one-dimensional lattice:\n",
    "\n",
    "$$\n",
    "H = \\sum_{n=1}^N h_{n,n+1}\n",
    "$$\n",
    "\n",
    "where $ N $ is the number of sites and we are assuming periodic boundary conditions. We now\n",
    "want to simulate the dynamics of this Hamiltonian in an efficient way using the\n",
    "aforementioned approximation Eq. [(14.1)](#equation-trotter-first). The simplest way to do this is to\n",
    "split the local terms into two groups, where terms within a group commute with each other,\n",
    "but not with terms in the other group. For example, we could split the Hamiltonian into even\n",
    "($ H_e $) and odd terms ($ H_o $):\n",
    "\n",
    "\n",
    "<a id='equation-hamsplit'></a>\n",
    "$$\n",
    "H_e = \\sum_n h_{(2n, 2n+1)}, \\qquad H_o = \\sum_n h_{(2n+1, 2n+2)}. \\tag{14.2}\n",
    "$$\n",
    "\n",
    "It is a simple exercise to show that the local terms within a group commute, as they act on\n",
    "non-overlapping sites. Therefore, if we can find a MPS representation of the initial state,\n",
    "the procedure for simulating the time evolution is as follows:\n",
    "\n",
    "![https://quantumghent.github.io/TensorTutorials/_static/figures/alg/tebd_mps.svg](https://quantumghent.github.io/TensorTutorials/_static/figures/alg/tebd_mps.svg)\n",
    "\n",
    "This procedure does not solve the problem as-is, as evaluating this network exactly would\n",
    "still require a bond dimension which grows exponentially with the number of layers $ m $.\n",
    "Instead, we can retain an efficient description by locally truncating the bond dimension, by\n",
    "computing an SVD an retaining only the largest $ \\chi $ singular values.\n",
    "\n",
    "![https://quantumghent.github.io/TensorTutorials/_static/figures/alg/tebd_trunc.svg](https://quantumghent.github.io/TensorTutorials/_static/figures/alg/tebd_trunc.svg)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "497b1f34",
   "metadata": {},
   "source": [
    "## Groundstate Search\n",
    "\n",
    "Another important problem in quantum physics is the determination of the groundstate of a\n",
    "given Hamiltonian. Again, this can be made more formal as follows: Given a Hamiltonian $ H $,\n",
    "is there a way to find the state $ \\ket{\\psi_0} $ that minimizes the expectation value\n",
    "$ \\bra{\\psi} H \\ket{\\psi} $.\n",
    "\n",
    "In fact, this problem faces the same difficulty as the one discussed above, namely that the\n",
    "naive solution strategy involves finding the eigenvector of the Hamiltonian matrix with the\n",
    "smallest eigenvalue, which again scales exponentially with the number of particles. However,\n",
    "as before, we can exploit the structure of the Hamiltonian to find a more efficient\n",
    "solution."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b19cfc68",
   "metadata": {},
   "source": [
    "### Imaginary Time Evolution\n",
    "\n",
    "In fact, the problem of finding groundstates can be mapped to the problem of simulating\n",
    "dynamics, by making use of a trick known as *imaginary time evolution*. The idea is to\n",
    "consider the time evolution operator $ e^{-i H t} $, but to replace the real time $ t $ by an\n",
    "imaginary time $ \\tau = i t $. If we now consider the limit $ \\tau \\to \\infty $ and deal with\n",
    "the normalization appropriately, we can see that applying the evolution operator to a state\n",
    "$ \\ket{\\psi_0} $ will effectively project it on its lowest energy eigenstate, as all other\n",
    "eigenstates will be damped out exponentially. In other words, we can find the groundstate of\n",
    "a Hamiltonian by simulating its dynamics for a sufficiently long imaginary time.\n",
    "\n",
    "$$\n",
    "\\lim_{\\tau \\to \\infty} e^{-i H \\tau} &= \\lim_{\\tau \\to \\infty} \\sum_{i=0}^\\infty e^{-E_i\n",
    "  \\tau} \\ket{\\psi_i} \\bra{\\psi_i} \\\\ \n",
    "&= \\lim_{\\tau \\to \\infty} e^{- E_0 \\tau} \\left(\\ket{\\psi_0} \\bra{\\psi_0} + \n",
    "  \\sum_{i>0}^\\infty e^{(-E_i + E_0) \\tau}\\ket{\\psi_i}\\bra{\\psi_i} \\right) \\\\\n",
    "&\\approx e^{-E_0 \\tau} \\ket{\\psi_0} \\bra{\\psi_0}\n",
    "$$\n",
    "\n",
    "where we have made use of the fact that all but the first term in the sum are damped out. In\n",
    "this regard, the groundstate search problem can also be tackled with the TEBD algorithm\n",
    "discussed above, by simply replacing the real time $ t $ by an imaginary time $ \\tau $ and\n",
    "continuing time-evolution until convergence is reached."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9e39eea",
   "metadata": {},
   "source": [
    "## Conclusion\n",
    "\n",
    "We have now seen a first example of algorithms that can be used for optimizing tensor\n",
    "networks, either to simulate dynamics or to find groundstates. We conclude by mentioning\n",
    "that this is only the tip of the iceberg, and that there exist many more algorithms that can\n",
    "be used to solve a variety of problems."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "938c37e6",
   "metadata": {},
   "source": [
    "## Outlook\n",
    "\n",
    "To close out this lecture, we briefly comment on the higher dimensional generalizations of\n",
    "the TEBD procedure and the difficulties this brings with it. For local quantum Hamiltonians\n",
    "in higher dimensions we can follow a similar procedure, where we split the full Hamiltonian\n",
    "into sum of parts that each only contain non-overlapping local terms. Time evolution can\n",
    "then be simulated by applying a similar sequence of layers, where in each layer we evolve\n",
    "with all local operators in a given Hamiltonian part in parallel.\n",
    "\n",
    "The problem with this approach however is that the local update step tebd_trunc is\n",
    "ill-conditioned for higher-dimensional networks if the full quantum state is is not taken\n",
    "into account for the truncation. Indeed, while in the one-dimensional case the rest of the\n",
    "network surrounding the sites we want to update can be brought into account exactly by\n",
    "working in appropriate gauge, this is not possible in general. Consider for example a\n",
    "general network where want to apply some update to the central site,\n",
    "\n",
    "![https://quantumghent.github.io/TensorTutorials/_static/figures/alg/tensor_network.svg](https://quantumghent.github.io/TensorTutorials/_static/figures/alg/tensor_network.svg)\n",
    "\n",
    "Since this network contains loops, there is no way to exactly capture the surrounding\n",
    "network in general. One instead has to resort to approximation techniques for the\n",
    "*environments* of a given update site, where the quality of the environment approximations\n",
    "directly affects the stability of the local update. The simplest way of doing this is to use\n",
    "the so-called *simple update* procedure [[Jiang *et al.*, 2008](https://quantumghent.github.io/TensorTutorials/../References.html#id18)] where all loops in the\n",
    "network are simply ignored and the environment is approximated by a product state,\n",
    "\n",
    "![https://quantumghent.github.io/TensorTutorials/_static/figures/alg/simple_update.svg](https://quantumghent.github.io/TensorTutorials/_static/figures/alg/simple_update.svg)\n",
    "\n",
    "More accurate results can be obtained by taking into account the full quantum state of the\n",
    "system in each local update by means of the *full update* procedure\n",
    "[[Jordan *et al.*, 2008](https://quantumghent.github.io/TensorTutorials/../References.html#id19)]. However, this gain in accuracy comes with a substantial\n",
    "increase in computational cost due to the full environment approximation at each step."
   ]
  }
 ],
 "metadata": {
  "date": 1708800322.0951757,
  "filename": "Algorithms.md",
  "kernelspec": {
   "display_name": "Julia",
   "language": "julia",
   "name": "julia-1.9"
  },
  "title": "A Simple Tensor Network Algorithm"
 },
 "nbformat": 4,
 "nbformat_minor": 5
}