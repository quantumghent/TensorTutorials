



<!DOCTYPE html>


<html lang="en" data-theme="light 
">

  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" />
    <title>2. Tensor Network Theory &#8212; TensorTutorials</title>
    
    <script src="https://unpkg.com/@popperjs/core@2.9.2/dist/umd/popper.min.js"></script>
    <script src="https://unpkg.com/tippy.js@6.3.1/dist/tippy-bundle.umd.js"></script>
    <script src="https://cdn.jsdelivr.net/npm/feather-icons/dist/feather.min.js"></script>
    
        <script>
            MathJax = {
            loader: {load: ['[tex]/boldsymbol', '[tex]/textmacros']},
            tex: {
                packages: {'[+]': ['boldsymbol', 'textmacros']},
                inlineMath: [['$', '$'], ['\\(', '\\)']],
                processEscapes: true,
                macros: {
                    "argmax" : "arg\\,max",
                    "argmin" : "arg\\,min",
                    "col"    : "col",
                    "Span"   :  "span",
                    "epsilon": "\\varepsilon",
                    "EE": "\\mathbb{E}",
                    "PP": "\\mathbb{P}",
                    "RR": "\\mathbb{R}",
                    "NN": "\\mathbb{N}",
                    "ZZ": "\\mathbb{Z}",
                    "aA": "\\mathcal{A}",
                    "bB": "\\mathcal{B}",
                    "cC": "\\mathcal{C}",
                    "dD": "\\mathcal{D}",
                    "eE": "\\mathcal{E}",
                    "fF": "\\mathcal{F}",
                    "gG": "\\mathcal{G}",
                    "hH": "\\mathcal{H}",
                }
            },
            svg: {
                fontCache: 'global',
                scale: 0.92,
                displayAlign: "center",
            },
            };
        </script>
    
    
  
  
  
  <script data-cfasync="false">
    document.documentElement.dataset.mode = localStorage.getItem("mode") || "light 
";
    document.documentElement.dataset.theme = localStorage.getItem("theme") || "light";
  </script>
  
  <!-- Loaded before other Sphinx assets -->
  <link href="../_static/styles/theme.css?digest=927b94d3fcb96560df09" rel="stylesheet" />
<link href="../_static/styles/bootstrap.css?digest=927b94d3fcb96560df09" rel="stylesheet" />
<link href="../_static/styles/pydata-sphinx-theme.css?digest=927b94d3fcb96560df09" rel="stylesheet" />

  
  <link href="../_static/vendor/fontawesome/6.1.2/css/all.min.css?digest=927b94d3fcb96560df09" rel="stylesheet" />
  <link rel="preload" as="font" type="font/woff2" crossorigin href="../_static/vendor/fontawesome/6.1.2/webfonts/fa-solid-900.woff2" />
<link rel="preload" as="font" type="font/woff2" crossorigin href="../_static/vendor/fontawesome/6.1.2/webfonts/fa-brands-400.woff2" />
<link rel="preload" as="font" type="font/woff2" crossorigin href="../_static/vendor/fontawesome/6.1.2/webfonts/fa-regular-400.woff2" />

    <link rel="stylesheet" type="text/css" href="../_static/pygments.css" />
    <link rel="stylesheet" type="text/css" href="../_static/quantumghent-book-theme.5e19e0a6c2e2247c14aaae6dbdd37c4f.css" />
    <link rel="stylesheet" type="text/css" href="../_static/togglebutton.css" />
    <link rel="stylesheet" type="text/css" href="../_static/copybutton.css" />
    <link rel="stylesheet" type="text/css" href="../_static/mystnb.4510f1fc1dee50b3e5859aac5469c37c29e427902b24a333a5f9fcb2f0b3ac41.css" />
    <link rel="stylesheet" type="text/css" href="../_static/sphinx-thebe.css" />
    <link rel="stylesheet" type="text/css" href="../_static/design-style.4045f2051d55cab465a707391d5b2007.min.css" />
  
  <!-- Pre-loaded scripts that we'll load fully later -->
  <link rel="preload" as="script" href="../_static/scripts/bootstrap.js?digest=927b94d3fcb96560df09" />
<link rel="preload" as="script" href="../_static/scripts/pydata-sphinx-theme.js?digest=927b94d3fcb96560df09" />
  <script src="../_static/vendor/fontawesome/6.1.2/js/all.min.js?digest=927b94d3fcb96560df09"></script>


    <script data-url_root="../" id="documentation_options" src="../_static/documentation_options.js"></script>
    <script src="../_static/jquery.js"></script>
    <script src="../_static/underscore.js"></script>
    <script src="../_static/_sphinx_javascript_frameworks_compat.js"></script>
    <script src="../_static/doctools.js"></script>
    <script src="../_static/clipboard.min.js"></script>
    <script src="../_static/copybutton.js"></script>
    <script src="../_static/scripts/sphinx-book-theme.js?digest=5a5c038af52cf7bc1a1ec88eea08e6366ee68824"></script>
    <script>let toggleHintShow = 'Click to show';</script>
    <script>let toggleHintHide = 'Click to hide';</script>
    <script>let toggleOpenOnPrint = 'true';</script>
    <script src="../_static/togglebutton.js"></script>
    <script>var togglebuttonSelector = '.toggle, .admonition.dropdown';</script>
    <script src="../_static/design-tabs.js"></script>
    <script src="../_static/quantumghent-book-theme.ef2ef6c3e8da75e1e736fb5fce08cde6.js"></script>
    <script async="async" src="https://www.googletagmanager.com/gtag/js?id=G-3PCWRLGWND"></script>
    <script>
                window.dataLayer = window.dataLayer || [];
                function gtag(){ dataLayer.push(arguments); }
                gtag('js', new Date());
                gtag('config', 'G-3PCWRLGWND');
            </script>
    <script>const THEBE_JS_URL = "https://unpkg.com/thebe@0.8.2/lib/index.js"
const thebe_selector = ".thebe,.cell"
const thebe_selector_input = "pre"
const thebe_selector_output = ".output, .cell_output"
</script>
    <script async="async" src="../_static/sphinx-thebe.js"></script>
    <script>window.MathJax = {"tex": {"macros": {"argmax": "arg\\,max", "argmin": "arg\\,min"}}, "options": {"processHtmlClass": "tex2jax_process|mathjax_process|math|output_area"}}</script>
    <script defer="defer" src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
    <script>DOCUMENTATION_OPTIONS.pagename = '1-Introduction/TensorNetworks';</script>
    <link rel="index" title="Index" href="../genindex.html" />
    <link rel="search" title="Search" href="../search.html" />
    <link rel="next" title="3. Getting started with Julia" href="Julia.html" />
    <link rel="prev" title="1. Quantum Many-Body Theory" href="QuantumManyBody.html" />

<!-- Normal Meta Tags -->
<meta name="author" context="QuantumGhent" />
<meta name="keywords" content="Julia, Tensor Networks, Quantum Many-Body Physics, Statistical Mechanics" />
<meta name="description" content=This website presents a set of lectures on Tensor Network methods />

<!-- Twitter tags -->
<meta name="twitter:card" content="summary" />
<meta name="twitter:site" content="@" />
<meta name="twitter:title" content="Tensor Network Theory"/>
<meta name="twitter:description" content="This website presents a set of lectures on Tensor Network methods">
<meta name="twitter:creator" content="@">
<meta name="twitter:image" content="">

<!-- Opengraph tags -->
<meta property="og:title" content="Tensor Network Theory" />
<meta property="og:type" content="website" />
<meta property="og:url" content="None" />
<meta property="og:image" content="" />
<meta property="og:description" content="This website presents a set of lectures on Tensor Network methods" />
<meta property="og:site_name" content="TensorTutorials" />
<meta name="theme-color" content="#ffffff" />

  </head>
<body>


    <span id="top"></span>

    <div class="qe-wrapper">

        <div class="qe-main">

            <div class="qe-page" id=1-Introduction/TensorNetworks>

                <div class="qe-page__toc">

                    <div class="inner">

                        
                        <div class="qe-page__toc-header">
                            On this page
                        </div>


                        <nav id="bd-toc-nav" class="qe-page__toc-nav">
                            <ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#overview">2.1. Overview</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#history">2.1.1. History</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#tensors">2.2. Tensors</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#linear-algebra-vectors-and-matrices">2.2.1. Linear Algebra – Vectors and Matrices</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#multi-linear-algebra-tensors-and-tensor-products">2.2.2. Multi-Linear Algebra: Tensors and Tensor Products</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#multi-linear-algebra-tensors-and-multi-linear-maps">2.2.3. Multi-Linear Algebra: Tensors and Multi-linear Maps</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#multi-linear-algebra-conclusion">2.2.4. Multi-Linear Algebra: Conclusion</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#graphical-notation-and-tensor-operations">2.3. Graphical Notation and Tensor Operations</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#indexing">2.3.1. Indexing</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#grouping-and-splitting-of-indices">2.3.2. Grouping and Splitting of Indices</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#outer-products">2.3.3. Outer Products</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#traces">2.3.4. Traces</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#contractions">2.3.5. Contractions</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#network-contractions-and-computational-complexity">2.4. Network Contractions and Computational Complexity</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#tensor-factorizations">2.5. Tensor Factorizations</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#eigenvalue-decomposition">2.5.1. Eigenvalue Decomposition</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#singular-value-decomposition">2.5.2. Singular Value Decomposition</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#qr-decomposition">2.5.3. QR Decomposition</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#nullspaces">2.5.4. Nullspaces</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#computational-complexity">2.6. Computational Complexity</a></li>
</ul>
                            <p class="logo">
                                
                                    
                                    <a href=https://quantumghent.github.io/><img src="../_static/logo.png" class="logo" alt="logo"></a>
                                    
                                
                            </p>

                            <p class="powered">Powered by <a href="https://jupyterbook.org/">Jupyter Book</a></p>

                        </nav>

                        <div class="qe-page__toc-footer">
                            
                            
                            <p><a href="#top"><strong>Back to top</strong></a></p>
                        </div>

                    </div>

                </div>

                <div class="qe-page__header">

                    <div class="qe-page__header-copy">

                        <p class="qe-page__header-heading"><a href="../intro.html">TensorTutorials</a></p>

                        <p class="qe-page__header-subheading">Tensor Network Theory</p>

                    </div>

                    <p class="qe-page__header-authors">QuantumGhent</p>

                </div> <!-- .page__header -->



                
                <main class="qe-page__content" role="main">
                    
                    <div>
                        
  <div class="tex2jax_ignore mathjax_ignore section" id="tensor-network-theory">
<h1><a class="toc-backref" href="#id2"><span class="section-number">2. </span>Tensor Network Theory</a><a class="headerlink" href="#tensor-network-theory" title="Permalink to this heading">#</a></h1>
<div class="contents topic" id="contents">
<p class="topic-title">Contents</p>
<ul class="simple">
<li><p><a class="reference internal" href="#tensor-network-theory" id="id2">Tensor Network Theory</a></p>
<ul>
<li><p><a class="reference internal" href="#overview" id="id3">Overview</a></p></li>
<li><p><a class="reference internal" href="#tensors" id="id4">Tensors</a></p></li>
<li><p><a class="reference internal" href="#graphical-notation-and-tensor-operations" id="id5">Graphical Notation and Tensor Operations</a></p></li>
<li><p><a class="reference internal" href="#network-contractions-and-computational-complexity" id="id6">Network Contractions and Computational Complexity</a></p></li>
<li><p><a class="reference internal" href="#tensor-factorizations" id="id7">Tensor Factorizations</a></p></li>
<li><p><a class="reference internal" href="#computational-complexity" id="id8">Computational Complexity</a></p></li>
</ul>
</li>
</ul>
</div>
<div class="section" id="overview">
<h2><a class="toc-backref" href="#id3"><span class="section-number">2.1. </span>Overview</a><a class="headerlink" href="#overview" title="Permalink to this heading">#</a></h2>
<p>In this lecture we will introduce the basic concepts of tensor network theory. We will start
with a brief overview of the history of tensor networks and their relevance to modern
physics. We will then introduce the basic mathematical concepts of tensor networks,
including multi-linear algebra and graphical notation. Finally, we will discuss the
computational complexity of tensor networks and their relevance to quantum many-body
physics.</p>
<p>This discussion is largely based on <span id="id1">[<a class="reference internal" href="../References.html#id3" title="Jacob C Bridgeman and Christopher T Chubb. Hand-waving and interpretive dance: an introductory course on tensor networks. Journal of Physics A: Mathematical and Theoretical, 50(22):223001, may 2017. URL: https://dx.doi.org/10.1088/1751-8121/aa6dc3, doi:10.1088/1751-8121/aa6dc3.">BC17</a>]</span>.</p>
<div class="section" id="history">
<h3><span class="section-number">2.1.1. </span>History<a class="headerlink" href="#history" title="Permalink to this heading">#</a></h3>
<p>The history of tensor networks is a fascinating journey through the evolution of profound
theoretical ideas and evolutions, as well as the development of computational methods and
tools. These ideas have been developed in a variety of contexts, but have been especially
relevant to the study of quantum physics and machine learning.</p>
<ol class="arabic simple">
<li><p>Early Foundations:</p></li>
</ol>
<ul class="simple">
<li><p>The roots of tensor networks can be traced back to the early development of linear algebra and matrix notation in the 19th century, pioneered by mathematicians like Arthur Cayley and James Sylvester.</p></li>
<li><p>The concept of tensors as multi-dimensional arrays of numbers began to emerge in the late 19th and early 20th centuries.</p></li>
</ul>
<ol class="arabic simple" start="2">
<li><p>Matrix Product States and DMRG:</p></li>
</ol>
<ul class="simple">
<li><p>The birth of modern tensor network theory can be attributed to the introduction of MPS in the 1960s (?).</p></li>
<li><p>One of the earliest, and still most widely used tensor network algorithm is DMRG. It was developed by Steven White in 1992, and provides one of the most efficient methods for simulating one-dimensional quantum many-body systems.</p></li>
</ul>
<ol class="arabic simple" start="3">
<li><p>Quantum Information Theory:</p></li>
</ol>
<ul class="simple">
<li><p>In the 1980s and 1990s, the field of quantum information theory began to emerge, driven by (add names here)</p></li>
<li><p>Concepts such as quantum entanglement and quantum information became central to the study of quantum many-body systems.</p></li>
</ul>
<ol class="arabic simple" start="4">
<li><p>Higher-Dimensional Tensor Networks:</p></li>
</ol>
<ul class="simple">
<li><p>As the field progressed, tensor network methods were extended to higher-dimensional systems, leading to the emergence of more general tensor network states (TNS)..</p></li>
<li><p>Two-dimensional tensor networks such as Projected Entangled Pair States (PEPS) and Multi-scale Entanglement Renormalization Ansatz (MERA) were introduced in the early 2000s.</p></li>
</ul>
<ol class="arabic simple" start="5">
<li><p>Tensor Networks in other disciplines:</p></li>
</ol>
<ul class="simple">
<li><p>Many of the concepts and methods developed in the context of tensor networks have been applied to other disciplines, one of the most prominent being machine learning.</p></li>
<li><p>Unsuprisingly, they also play a central role in quantum computing, where tensor network algorithms provide a natural language to explore quantum circuit simulations.</p></li>
</ul>
<ol class="arabic simple" start="6">
<li><p>Ongoing Research and Applications</p></li>
</ol>
<ul class="simple">
<li><p>Tensor network theory continues to be a vibrant and evolving field with ongoing research in various directions, such as the development of efficient tensor contraction algorithms, the application of tensor networks for understanding quantum phases of matter, the development of tensor network algorithms for quantum computing, and the application of tensor networks to machine learning.</p></li>
</ul>
</div>
</div>
<div class="section" id="tensors">
<h2><a class="toc-backref" href="#id4"><span class="section-number">2.2. </span>Tensors</a><a class="headerlink" href="#tensors" title="Permalink to this heading">#</a></h2>
<p>Before discussing tensor networks, it is necessary to understand what tensors are.
Furthermore, before really understanding tensors, it is instructive to reiterate some basic
concepts of linear algebra for the case of vectors and matrices, which are nothing but
specific cases of tensors. In fact, many of the concepts and ideas that are introduced and
discussed are defined in terms of thinking of tensors as vectors or matrices.</p>
<p>In what follows, vectors and matrices will be thought of from the viewpoint of computers,
where they are represented using regular one- and two-dimensional arrays of either real or
complex numbers. Nevertheless, much of the discussion can be trivially generalized to
arbitrary vector spaces and linear maps.</p>
<div class="section" id="linear-algebra-vectors-and-matrices">
<h3><span class="section-number">2.2.1. </span>Linear Algebra – Vectors and Matrices<a class="headerlink" href="#linear-algebra-vectors-and-matrices" title="Permalink to this heading">#</a></h3>
<p>In general, a vector is an object in a vector space, which can be described by a list of
numbers that correspond to the components of the vector in some basis. For example, a vector
in a two-dimensional space is in its most general form described by
<span class="math notranslate nohighlight">\(\vec{v} = \left[v_1, v_2\right]^T\)</span>.</p>
<p>As a reminder, the defining properties of vector spaces make sure that the following
operations are well-defined:</p>
<ul class="simple">
<li><p>Vectors can be added together, i.e. <span class="math notranslate nohighlight">\(\vec{v} + \vec{w}\)</span> is a vector.</p></li>
<li><p>Vectors can be multiplied by scalars, i.e. <span class="math notranslate nohighlight">\(\alpha \vec{v}\)</span> is a vector.</p></li>
<li><p>These operations behave as expected, i.e. there is a notion of associativity, commutativity, and distributivity.</p></li>
</ul>
<p>Given two such vector spaces (not necessarily distinct) it is possible to define a linear
map between them, which is just a function that preserves the vector space structure. In
other words, a linear map <span class="math notranslate nohighlight">\(A \colon W ← V\)</span> maps vectors from one vector space <span class="math notranslate nohighlight">\(V\)</span> to another
vector space <span class="math notranslate nohighlight">\(W\)</span>. Because of the structure of vector spaces, and the requirement of
linearity, such a map is completely determined by its action on the basis vectors of <span class="math notranslate nohighlight">\(V\)</span>.
This leads in a very natural way to the notion of a matrix by considering the following
construction, where <span class="math notranslate nohighlight">\(v_i\)</span> are the basis vectors of <span class="math notranslate nohighlight">\(V\)</span> and <span class="math notranslate nohighlight">\(w_i\)</span> are the basis vectors of <span class="math notranslate nohighlight">\(W\)</span>:</p>
<div class="math notranslate nohighlight" id="equation-eq-linear-map">
<span class="eqno">(2.1)<a class="headerlink" href="#equation-eq-linear-map" title="Permalink to this equation">#</a></span>\[\begin{split}\begin{align}
A &amp; : &amp; W \leftarrow V\\
A &amp; : &amp; v ↦ w = A(v) = \sum_j A_{ij} v_j
\end{align}\end{split}\]</div>
<p>where <span class="math notranslate nohighlight">\(A_{ij}\)</span> are the components of the matrix <span class="math notranslate nohighlight">\(A\)</span> in the basis <span class="math notranslate nohighlight">\(v_i\)</span> and <span class="math notranslate nohighlight">\(w_j\)</span>. In other
words, the abstract notion of a linear map between vector spaces can be represented by a
concrete matrix, and the action of the map is nothing but the usual matrix product.</p>
<p>In particular, it is instructive to think of the columns of the matrix <span class="math notranslate nohighlight">\(A\)</span> as labelling the
components of the input vector space, while the rows label the component of the output
vector space.</p>
</div>
<div class="section" id="multi-linear-algebra-tensors-and-tensor-products">
<h3><span class="section-number">2.2.2. </span>Multi-Linear Algebra: Tensors and Tensor Products<a class="headerlink" href="#multi-linear-algebra-tensors-and-tensor-products" title="Permalink to this heading">#</a></h3>
<p>Using the same logic as above, it is possible to generalize the notion of a linear map by
making use of the <a class="reference external" href="https://en.wikipedia.org/wiki/Tensor_product">tensor product</a>, which is
nothing but an operation that can combine two vector spaces <span class="math notranslate nohighlight">\(V\)</span> and <span class="math notranslate nohighlight">\(W\)</span> into a new vector
space <span class="math notranslate nohighlight">\(V \otimes W\)</span>. The tensor product is defined in such a way that the combination of
vectors from the original vector spaces preserves a natural notion of linearity, i.e. the
following equality holds for all vectors <span class="math notranslate nohighlight">\(v \in V\)</span>, <span class="math notranslate nohighlight">\(w \in W\)</span>, and scalars <span class="math notranslate nohighlight">\(\lambda\)</span>:</p>
<div class="math notranslate nohighlight" id="equation-eq-tensor-product">
<span class="eqno">(2.2)<a class="headerlink" href="#equation-eq-tensor-product" title="Permalink to this equation">#</a></span>\[(\lambda v) \otimes w = v \otimes (\lambda w) = \lambda (v \otimes w)\]</div>
<p>This new vector space can be equipped with a canonical basis, which is constructed by taking
the tensor product of the basis vectors of the original vector spaces. For example, if <span class="math notranslate nohighlight">\(V\)</span>
and <span class="math notranslate nohighlight">\(W\)</span> are two-dimensional vector spaces with basis vectors <span class="math notranslate nohighlight">\(v_i\)</span> and <span class="math notranslate nohighlight">\(w_j\)</span>, respectively,
then the basis vectors of <span class="math notranslate nohighlight">\(V \otimes W\)</span> are given by <span class="math notranslate nohighlight">\(v_i \otimes w_j\)</span>. In other words, the
vectors in <span class="math notranslate nohighlight">\(V \otimes W\)</span> are linear combinations of all combinatinos of the basis vectors of
<span class="math notranslate nohighlight">\(V\)</span> and <span class="math notranslate nohighlight">\(W\)</span>.</p>
<p>When considering how to represent a vector in this new vector space, it can be written as a
list of numbers that correspond to the components of the vector in that basis. For example,
a vector in <span class="math notranslate nohighlight">\(V \otimes W\)</span> is described by:</p>
<div class="math notranslate nohighlight" id="equation-eq-tensor-basis">
<span class="eqno">(2.3)<a class="headerlink" href="#equation-eq-tensor-basis" title="Permalink to this equation">#</a></span>\[t = \sum_{i_1,i_2} t_{i_1i_2} (v_{i_1} \otimes w_{i_2})\]</div>
<p>Here, the tentative name <span class="math notranslate nohighlight">\(t\)</span> was used to denote that this is in fact a tensor, where
<span class="math notranslate nohighlight">\(t_{i_1i_2}\)</span> are the components of that tensor <span class="math notranslate nohighlight">\(t\)</span> in the basis <span class="math notranslate nohighlight">\(v_{i_1} \otimes w_{i_2}\)</span>.
Because of the induced structure of the tensor product, it is more natural and very common
to express this object not just as a list of numbers, but by reshaping that list into a
matrix. In this case, the components of the <span class="math notranslate nohighlight">\(i_1\)</span>-th row correspond to basis vectors that
are built from <span class="math notranslate nohighlight">\(v_{i_1}\)</span>, and similarly the <span class="math notranslate nohighlight">\(i_2\)</span>-th column corresponds to basis vectors
that are built from <span class="math notranslate nohighlight">\(w_{i_2}\)</span>.</p>
<p>As the tensor product can be generalized to more than two vector spaces, this finally leads
to the general definition of a tensor as an element of the vector space that is built up
from the tensor product of an arbitrary number of vector spaces. Additionally, the
components of these objects are then naturally laid out in a multi-dimensional array, which
is then by a slight misuse of terminology also called a tensor.</p>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>The reshaping operation of components from a list of numbers into a multi-dimensional array
is nothing but a mapping between linear indices <span class="math notranslate nohighlight">\(I\)</span> and Cartesian indices <span class="math notranslate nohighlight">\(i_1, i_2, \cdots,
i_N\)</span>. This is a very common and useful trick which allows reinterpreting tensors as vectors,
or vice versa.</p>
</div>
</div>
<div class="section" id="multi-linear-algebra-tensors-and-multi-linear-maps">
<h3><span class="section-number">2.2.3. </span>Multi-Linear Algebra: Tensors and Multi-linear Maps<a class="headerlink" href="#multi-linear-algebra-tensors-and-multi-linear-maps" title="Permalink to this heading">#</a></h3>
<p>Due to the fact that the tensor product of vector spaces is a vector space in of itself, it
is again possible to define linear maps between such vector spaces. Keeping in mind the
definition of a linear map from <a class="reference internal" href="#equation-eq-linear-map">(2.1)</a>, the columns now label components of the
input vector space, while the rows label components of the output vector space. Now however,
the components of the input and output vector spaces are themselves comprised of a
combination of basis vectors from the original vector spaces. If a linear order of these
combinations can be established, the linear map can again be represented by a matrix:</p>
<div class="math notranslate nohighlight" id="equation-eq-multilinear-map">
<span class="eqno">(2.4)<a class="headerlink" href="#equation-eq-multilinear-map" title="Permalink to this equation">#</a></span>\[\begin{split}\begin{align}
A 	&amp; : &amp; W_1 \otimes W_2 \otimes \cdots \otimes W_M \leftarrow V_1 \otimes V_2 \otimes \cdots \otimes V_N \\
	&amp; 	&amp; v_1 \otimes v_2 \otimes \cdots \otimes v_N ↦ A(v) \\
	&amp; 	&amp;= w_1 \otimes w_2 \otimes \cdots \otimes w_M \\
	&amp; 	&amp;= \sum_{j_1,j_2,\cdots,j_N} A_{i_1,i_2,\cdots,i_M;j_1,j_2,\cdots,j_N} v_{1,j} \otimes v_{2,j} \otimes \cdots \otimes v_{N,j} \\
	&amp; 	&amp;= \sum_{J} A_{I;J} v_J \\
\end{align}\end{split}\]</div>
<p>The attentive reader might have already noted that the definition of a linear map as a
matrix strongly resembles the definition of a vector in a tensor product vector space. This
is not a coincidence, and in fact the two can easily be identified by considering the
following identification (isomorphism):</p>
<div class="math notranslate nohighlight" id="equation-eq-tensor-isomorphism">
<span class="eqno">(2.5)<a class="headerlink" href="#equation-eq-tensor-isomorphism" title="Permalink to this equation">#</a></span>\[V \leftarrow W \cong V \otimes W^* \]</div>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>For finite-dimensional real or complex vector spaces without additional structure, this
isomorphism is <em>trivial</em> and is nothing but the reshaping operation of the components of a
vector into a matrix. However, note that this is a choice, which is not unique, and already
differs for
<a class="reference external" href="https://en.wikipedia.org/wiki/Row-_and_column-major_order">row- and column-major order</a>. In
a more general setting, the identification between <span class="math notranslate nohighlight">\(V \otimes W^*\)</span> and <span class="math notranslate nohighlight">\(V \leftarrow W\)</span> is
not an equivalence but an isomorphism. This means that it is still possible to relate one
object to the other, but the operation is not necessarily trivial.</p>
</div>
</div>
<div class="section" id="multi-linear-algebra-conclusion">
<h3><span class="section-number">2.2.4. </span>Multi-Linear Algebra: Conclusion<a class="headerlink" href="#multi-linear-algebra-conclusion" title="Permalink to this heading">#</a></h3>
<p>The entire discussion can be summarized and leads to the following equivalent definitions of a tensor:</p>
<ul class="simple">
<li><p>A tensor is an element of a tensor product of vector spaces, which can be represented as a multi-dimensional array of numbers that indicate the components along the constituent basis vectors. (a tensor is vector-like)</p></li>
<li><p>A tensor is a multi-linear map between vector spaces, which can be represented as a matrix that represents the action of the map on the basis vectors of the input vector space. (a tensor is matrix-like)</p></li>
</ul>
<p>The equivalence of these two definitions leads to the lifting of many important facets of linear algebra to the multi-linear setting.</p>
</div>
</div>
<div class="section" id="graphical-notation-and-tensor-operations">
<h2><a class="toc-backref" href="#id5"><span class="section-number">2.3. </span>Graphical Notation and Tensor Operations</a><a class="headerlink" href="#graphical-notation-and-tensor-operations" title="Permalink to this heading">#</a></h2>
<p>One of the main advantages of tensor networks is that they admit a very intuitive graphical
notation, which greatly simplifies the expressions involving numerous indices. This notation
is based on the idea of representing a single tensor as a node in a graph, where the indices
of the tensor are depicted by legs sticking out of it, one for each vector space. As an example, a rank-four tensor <span class="math notranslate nohighlight">\(R\)</span> can be represented as:</p>
<img alt="../_images/R-tensor.svg" class="align-center" id="r-tensor" src="../_images/R-tensor.svg" /><div class="section" id="indexing">
<h3><span class="section-number">2.3.1. </span>Indexing<a class="headerlink" href="#indexing" title="Permalink to this heading">#</a></h3>
<p>In this notation, the individual components of the tensor can be recoverd by fixing the open
legs of a diagram to some value, and the resulting diagram is then a scalar. For example,
the component <span class="math notranslate nohighlight">\(R_{i_1,i_2,i_3,i_4}\)</span> is given by:</p>
<!-- TODO: insert figure -->
</div>
<div class="section" id="grouping-and-splitting-of-indices">
<h3><span class="section-number">2.3.2. </span>Grouping and Splitting of Indices<a class="headerlink" href="#grouping-and-splitting-of-indices" title="Permalink to this heading">#</a></h3>
<p>Because of the isomorphism {eq}{eq:tensor_isomorphism}, the legs of the tensor can be freely
moved around, as long as their order is preserved. In some contexts the shape of
the node and the direction of the tensor can imply certain properties, such as making an
explicit distinction between the isomorphic representations, but in what follows we will not
make this distinction.</p>
<p>Furthermore, this naturally gives a notion of grouping and splitting of indices, which is just a reinterpretation of a set of neighbouring vector spaces as a single vector space, and the inverse operation. For example, the following diagrams are equivalent:</p>
<img alt="../_images/grouping.svg" class="align-center" id="grouping" src="../_images/grouping.svg" /><p>Owing to the freedom in choice of basis, the precise details of grouping and splitting are
not unique. One specific choice of convention is the tensor product basis, which is
precisely the one we have used in the discussion of multi-linear algebra. More concretely,
one choice that is often used is the <em>Kronecker product</em>, which in the setting of
column-major ordering is given explicitly by grouping indices as follows:</p>
<div class="math notranslate nohighlight" id="equation-eq-kronecker-product">
<span class="eqno">(2.6)<a class="headerlink" href="#equation-eq-kronecker-product" title="Permalink to this equation">#</a></span>\[I \coloneq i_1 + d_1 * (i_2 - 1) + d_1 * d_2 * (i_3 - 1) + d_1 * d_2 * d_3 * (i_4 - 1) + \cdots\]</div>
<p>Here <span class="math notranslate nohighlight">\(d_i\)</span> is the dimension of the corresponding vector space, and <span class="math notranslate nohighlight">\(I\)</span> is the resulting
linear index. Note again that so long as the chosen convention is consistent, the precise
method of grouping and splitting is immaterial.</p>
</div>
<div class="section" id="outer-products">
<h3><span class="section-number">2.3.3. </span>Outer Products<a class="headerlink" href="#outer-products" title="Permalink to this heading">#</a></h3>
<p>Of course, in order to really consider a tensor <em>network</em>, it is necessary to consider
diagrams that consist of multiple tensors, or in other words of multiple nodes. The simplest
such diagram represents the <em>outer product</em> of two tensors. This is represented by two
tensors being placed next to eachother. The value of the resulting network is simply the
product of the constituents. For example, the outer product of a rank three tensor <span class="math notranslate nohighlight">\(A\)</span> and a
rank two tensor <span class="math notranslate nohighlight">\(B\)</span> is given by:</p>
<img alt="../_images/outer-product.svg" class="align-center" id="outer-product" src="../_images/outer-product.svg" /></div>
<div class="section" id="traces">
<h3><span class="section-number">2.3.4. </span>Traces<a class="headerlink" href="#traces" title="Permalink to this heading">#</a></h3>
<p>More complicated diagrams can be constructed by joining some of the legs of the
constituents. In a matter similar to the conventional Einstein notation, this implies a
summation over the corresponding indices.</p>
<p>If two legs from a single tensor are joined, this signifies a (partial) <em>trace</em> of a tensor
over these indices. For example, the trace of a rank three tensor <span class="math notranslate nohighlight">\(A\)</span> over two of its
indices is given by:</p>
<img alt="../_images/trace.svg" class="align-center" id="trace" src="../_images/trace.svg" /><p>In this notation, the cyclic property of the trace follows trivially by sliding one of the
matrices around the loop of the diagram. As this only changes the placement of the tensors
in the network, and not the value, the graphic proof of <span class="math notranslate nohighlight">\(\tr (AB) = \tr (BA)\)</span> is found.</p>
<img alt="../_images/trace-cyclic.svg" class="align-center" id="trace-cyclic" src="../_images/trace-cyclic.svg" /></div>
<div class="section" id="contractions">
<h3><span class="section-number">2.3.5. </span>Contractions<a class="headerlink" href="#contractions" title="Permalink to this heading">#</a></h3>
<p>The most common tensor operation used is <em>contraction</em>, which is the joining of legs from
different tensors. This can equivalently be thought of as a tensor product followed by a
trace. For example, the contraction between two pairs of indices of two rank-three tensors
is drawn as:</p>
<img alt="../_images/contraction.svg" class="align-center" id="contraction" src="../_images/contraction.svg" /><p>Famililiar examples of contraction are vector inner products, matrix-vector multiplication,
matrix-matrix multiplication, and matrix traces.</p>
<!-- TODO: insert figure -->
</div>
</div>
<div class="section" id="network-contractions-and-computational-complexity">
<h2><a class="toc-backref" href="#id6"><span class="section-number">2.4. </span>Network Contractions and Computational Complexity</a><a class="headerlink" href="#network-contractions-and-computational-complexity" title="Permalink to this heading">#</a></h2>
</div>
<div class="section" id="tensor-factorizations">
<h2><a class="toc-backref" href="#id7"><span class="section-number">2.5. </span>Tensor Factorizations</a><a class="headerlink" href="#tensor-factorizations" title="Permalink to this heading">#</a></h2>
<p>Linear maps admit various kinds of factorizations, which are instrumental in a variety of
applications. They can be used to generate orthogonal bases, to find low-rank
approximations, or to find eigenvalues and vectors. In the context of tensors, the
established theory for factorizations of matrices can be generalized by interpreting them as
linear maps, and then applying the same factorization to the corresponding matrix partition
of the constituent vector spaces in a codomain and domain, after which everything
representation. Thus, the only additional piece of information needed consists of a carries
over. In this section we will only discuss the most common factorizations of tensors, but
the reasoning can be generalized to any factorization of linear maps.</p>
<div class="section" id="eigenvalue-decomposition">
<h3><span class="section-number">2.5.1. </span>Eigenvalue Decomposition<a class="headerlink" href="#eigenvalue-decomposition" title="Permalink to this heading">#</a></h3>
<p>The <a class="reference external" href="https://en.wikipedia.org/wiki/Eigendecomposition_of_a_matrix">Eigen decomposition of a matrix</a>
<span class="math notranslate nohighlight">\(A\)</span> is a factorization of the form:</p>
<div class="math notranslate nohighlight">
\[A = V \Lambda V^{-1}\]</div>
<p>where <span class="math notranslate nohighlight">\(V\)</span> is a matrix of eigenvectors, and <span class="math notranslate nohighlight">\(\Lambda\)</span> is a diagonal matrix of eigenvalues. In
particular, the set of eigenvectors form a basis for all possible products <span class="math notranslate nohighlight">\(Ax\)</span>, which is
the same as the image of the corresponding matrix transformation. For normal matrices, these
eigenvectors can be made orthogonal and the resulting decomposition is also called the
<em>spectral decomposition</em>.</p>
<p>The eigenvalue decomposition mostly finds it use in the context of linear equations of the form:</p>
<div class="math notranslate nohighlight">
\[Av = \lambda v\]</div>
<p>where <span class="math notranslate nohighlight">\(v\)</span> is an eigenvector of <span class="math notranslate nohighlight">\(A\)</span> with eigenvalue <span class="math notranslate nohighlight">\(\lambda\)</span>.</p>
<p>For tensors, the eigenvalue decomposition is defined similarly, and the equivalent equation
is diagrammatically represented as:</p>
<!-- TODO: insert image -->
</div>
<div class="section" id="singular-value-decomposition">
<h3><span class="section-number">2.5.2. </span>Singular Value Decomposition<a class="headerlink" href="#singular-value-decomposition" title="Permalink to this heading">#</a></h3>
<img alt="../_images/svd.svg" class="align-center" id="svd" src="../_images/svd.svg" /></div>
<div class="section" id="qr-decomposition">
<h3><span class="section-number">2.5.3. </span>QR Decomposition<a class="headerlink" href="#qr-decomposition" title="Permalink to this heading">#</a></h3>
</div>
<div class="section" id="nullspaces">
<h3><span class="section-number">2.5.4. </span>Nullspaces<a class="headerlink" href="#nullspaces" title="Permalink to this heading">#</a></h3>
</div>
</div>
<div class="section" id="computational-complexity">
<h2><a class="toc-backref" href="#id8"><span class="section-number">2.6. </span>Computational Complexity</a><a class="headerlink" href="#computational-complexity" title="Permalink to this heading">#</a></h2>
<ol class="arabic simple" start="3">
<li><p>Tensor Networks</p>
<ul class="simple">
<li><p>context, history, purpose, relevance</p></li>
<li><p>multi-linear algebra</p></li>
<li><p>graphical notation</p></li>
<li><p>computational complexity</p></li>
</ul>
</li>
</ol>
</div>
</div>

    <script type="text/x-thebe-config">
    {
        requestKernel: true,
        binderOptions: {
            repo: "binder-examples/jupyter-stacks-datascience",
            ref: "master",
        },
        codeMirrorConfig: {
            theme: "abcdef",
            mode: "julia-1.9"
        },
        kernelOptions: {
            name: "julia-1.9",
            path: "./1-Introduction"
        },
        predefinedOutput: true
    }
    </script>
    <script>kernelName = 'julia-1.9'</script>

                    </div>
                    
                </main> <!-- .page__content -->
                


                <footer class="qe-page__footer">

                    <p><a href="https://creativecommons.org/licenses/by-sa/4.0/"><img src="https://licensebuttons.net/l/by-sa/4.0/80x15.png"></a></p>

                    <p>Creative Commons License &ndash; This work is licensed under a Creative Commons Attribution-ShareAlike 4.0 International.</p>

                </footer> <!-- .page__footer -->

            </div> <!-- .page -->

            

            
            <div class="qe-sidebar bd-sidebar inactive" id="site-navigation">

                <div class="qe-sidebar__header">


                    Contents

                </div>

                <nav class="qe-sidebar__nav" id="qe-sidebar-nav" aria-label="Main navigation">
                    <p aria-level="2" class="caption" role="heading">
 <span class="caption-text">
  Introduction
 </span>
</p>
<ul class="current nav bd-sidenav nav sidenav_l1">
 <li class="toctree-l1">
  <a class="reference internal" href="QuantumManyBody.html">
   1. Quantum Many-Body Theory
  </a>
 </li>
 <li class="toctree-l1 current active active">
  <a class="current reference internal" href="#">
   2. Tensor Network Theory
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="Julia.html">
   3. Getting started with Julia
  </a>
 </li>
</ul>
<p aria-level="2" class="caption" role="heading">
 <span class="caption-text">
  Tensors
 </span>
</p>
<ul class="nav bd-sidenav nav sidenav_l1">
 <li class="toctree-l1">
  <a class="reference internal" href="../2-Tensors/TensorKit.html">
   4. TensorKit.jl
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../2-Tensors/TensorOperations.html">
   5. TensorOperations.jl
  </a>
 </li>
</ul>
<p aria-level="2" class="caption" role="heading">
 <span class="caption-text">
  Matrix Product States
 </span>
</p>
<ul class="nav bd-sidenav nav sidenav_l1">
 <li class="toctree-l1">
  <a class="reference internal" href="../3-MatrixProductStates/MatrixProductStates.html">
   6. Matrix Product States
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../3-MatrixProductStates/MatrixProductOperators.html">
   7. Matrix Product Operators
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../3-MatrixProductStates/InfiniteMPS.html">
   8. Infinite Matrix Product States
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../3-MatrixProductStates/Algorithms.html">
   9. Algorithms
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../3-MatrixProductStates/Applications.html">
   10. Applications
  </a>
 </li>
</ul>
<p aria-level="2" class="caption" role="heading">
 <span class="caption-text">
  Other
 </span>
</p>
<ul class="nav bd-sidenav nav sidenav_l1">
 <li class="toctree-l1">
  <a class="reference internal" href="../References.html">
   11. References
  </a>
 </li>
</ul>

                </nav>

                <div class="qe-sidebar__footer">

                </div>

            </div> <!-- .sidebar -->
            
        </div> <!-- .main -->

        <div class="qe-toolbar">

            <div class="qe-toolbar__inner">

                <ul class="qe-toolbar__main">
                    <li data-tippy-content="Table of Contents" class="btn__sidebar"><i data-feather="menu"></i></li>
                    <li data-tippy-content="Home"><a href="../intro.html"><i data-feather="home"></i></a></li>
                    <li><a href="https://quantumghent.github.io/" title="">QuantumGroup@UGent</a></li>
                    <li><a href="https://github.com/quantumghent" title="GitHub" rel="external nofollow noopener" target="_blank"><i class="fab fa-github"></i></a></li>
                </ul>

                <ul class="qe-toolbar__links">
                    <li class="btn__search">
                        <form action="../search.html" method="get">
                            <input type="search" class="form-control" name="q" id="search-input" placeholder="Search..." aria-label="Search..." autocomplete="off" accesskey="k">
                            <i data-feather="search" id="search-icon"></i>
                        </form>
                    </li>
                    <li data-tippy-content="Fullscreen" class="btn__fullscreen"><i data-feather="maximize"></i></li>
                    <li data-tippy-content="Increase font size" class="btn__plus"><i data-feather="plus-circle"></i></li>
                    <li data-tippy-content="Decrease font size" class="btn__minus"><i data-feather="minus-circle"></i></li>
                    <li data-tippy-content="Change contrast" class="btn__contrast"><i data-feather="sunset"></i></li>
                    <li class="settings-button" id="settingsButton"><div data-tippy-content="Launch Notebook"><i data-feather="play-circle"></i></div></li>
                        <li data-tippy-content="Download PDF" onClick="window.print()"><i data-feather="file"></i></li>
                    <li data-tippy-content="View Source"><a target="_blank" href="https://github.com/quantumghent/TensorTutorials/blob/main/lectures/1-Introduction/TensorNetworks.md" download><i data-feather="github"></i></a></li>
                </ul>

            </div>

        </div> <!-- .toolbar -->
        <div id="downloadPDFModal" style="display: none;">
            <ul class="pdf-options" style="display: block;">
                <li class="download-pdf-book" onClick="window.print()">
                    <p>Lecture (PDF)</p>
                </li>
                <li class="download-pdf-file">
                    <a href="" download><p>Book (PDF)</p></a>
                </li>
            </ul>
        </div>
        <div id="settingsModal" style="display: none;">
            <p class="modal-title"> Notebook Launcher </p>
            <div class="modal-desc">
            <p>
                Choose public or private cloud service for "Launch" button.
            </p>
            </div>
            <p class="modal-subtitle">Select a server</p>
            <ul class="modal-servers">
            <li class="active launcher-public">
                <span class="label">Public</span>
                <select id="launcher-public-input">
                
                    <option value="https://colab.research.google.com/github/quantumghent/TensorTutorials/blob/main/1-Introduction/TensorNetworks.ipynb">Colab</option>
                
                </select>
                <i class="fas fa-check-circle"></i>
            </li>
            <li class="launcher-private">
                <span class="label">Private</span>
                <input type="text" id="launcher-private-input" data-repourl="https://github.com/quantumghent/TensorTutorials" data-urlpath="tree/TensorTutorials/1-Introduction/TensorNetworks.ipynb" data-branch=main>
                <i class="fas fa-check-circle"></i>
            </li>
            </ul>
            <p class="launch"><a href="https://colab.research.google.com/github/quantumghent/TensorTutorials/blob/main/1-Introduction/TensorNetworks.ipynb" id="advancedLaunchButton" target="_blank">Launch Notebook</a></p>
            <script>
                // QuantEcon Notebook Launcher
                const launcherTypeElements = document.querySelectorAll('#settingsModal .modal-servers li');
                // Highlight the server type if previous selection exists
                if (typeof localStorage.launcherType !== 'undefined') {
                  for (var i = 0; i < launcherTypeElements.length; i++) {
                    launcherTypeElements[i].classList.remove('active');
                    if ( launcherTypeElements[i].classList.contains(localStorage.launcherType) ) {
                      launcherTypeElements[i].classList.add('active');
                    }
                  }
                }
                // Highlight server type on click and set local storage value
                for (var i = 0; i < launcherTypeElements.length; i++) {
                  launcherTypeElements[i].addEventListener('click', function() {
                    for (var j = 0; j < launcherTypeElements.length; j++) {
                      launcherTypeElements[j].classList.remove('active');
                    }
                    this.classList.add('active');
                    if ( this.classList.contains('launcher-private') ) {
                      localStorage.launcherType = 'launcher-private';
                    } else if ( this.classList.contains('launcher-public') ) {
                      localStorage.launcherType = 'launcher-public';
                    }
                    setLaunchServer();
                  })
                }
                const launcherPublic = document.getElementById('launcher-public-input');
                const launcherPrivate = document.getElementById('launcher-private-input');
                const pageName = "1-Introduction/TensorNetworks";
                const repoURL = "https://github.com/quantumghent/TensorTutorials";
                const urlPath = "tree/TensorTutorials/1-Introduction/TensorNetworks.ipynb";
                const branch = "main"
                const launchNotebookLink = document.getElementById('advancedLaunchButton');

                // Highlight public server option if previous selection exists
                if (typeof localStorage.launcherPublic !== 'undefined') {
                  launcherPublic.value = localStorage.launcherPublic;
                }
                // Update local storage upon public server selection
                launcherPublic.addEventListener('change', (event) => {
                  setLaunchServer();
                });
                // Populate private server input if previous entry exists
                if (typeof localStorage.launcherPrivate !== 'undefined') {
                  launcherPrivate.value = localStorage.launcherPrivate;
                }
                // Update local storage when a private server is entered
                launcherPrivate.addEventListener('input', (event) => {
                  setLaunchServer();
                });

                // Function to update the "Launch Notebook" link href
                function setLaunchServer() {
                  launchNotebookLink.removeAttribute("style")
                  if ( localStorage.launcherType == 'launcher-private' ) {
                    let repoPrefix = "/jupyter/hub/user-redirect/git-pull?repo=" + repoURL + "&branch=" + branch + "&urlpath=" + urlPath;
                    launcherPrivateValue = launcherPrivate.value
                    if (!launcherPrivateValue) {
                        launchNotebookLink.removeAttribute("href")
                        launchNotebookLink.style.background = "grey"
                        return
                    }
                    localStorage.launcherPrivate = launcherPrivateValue;
                    privateServer = localStorage.launcherPrivate.replace(/\/$/, "")
                    if (!privateServer.includes("http")) {
                        privateServer = "http://" + privateServer
                    }
                    launchNotebookLinkURL = privateServer + repoPrefix;
                  } else if ( localStorage.launcherType == 'launcher-public' ) {
                    launcherPublicValue = launcherPublic.options[launcherPublic.selectedIndex].value;
                    localStorage.launcherPublic = launcherPublicValue;
                    launchNotebookLinkURL = localStorage.launcherPublic;
                  }
                  if (launchNotebookLinkURL) launchNotebookLink.href = launchNotebookLinkURL;
                }
                // Check if user has previously selected a server
                if ( (typeof localStorage.launcherPrivate !== 'undefined') || (typeof localStorage.launcherPublic !== 'undefined') ) {
                  setLaunchServer();
                }
                </script>

        </div>

    </div> <!-- .wrapper-->
  </body>
</html>